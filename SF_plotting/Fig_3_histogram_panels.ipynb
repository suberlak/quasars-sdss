{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on CRTS_sel_g_cut_vs_r_cut.ipynb,   taking only the code needed to make Fig. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A testbed for making Fig.3 :  the 4 x 4 histogram plot. It shows that   0   < log(tau) < 1.7 (short timescales bin), does not exhibit any variability, because chi_ij for qso and stars is almost undistinguishable for uncorrected points. \n",
    "\n",
    "The files in  SF_plotting/Histogram_r_cut_starsB_qso/    are described in README. \n",
    "\n",
    "To make them  one would run points 1-10  (numeration inherited from CRTS_sel_g_cut_vs_r_cut.ipynb )   for different mag cuts :  17-18 ,  18-18.5 ,  18.5-19 , thus producing  8 files per cut (4 for qso,  4 for Blue Stars ) . \n",
    "\n",
    "Thus saved in SF_plotting/Histogram_r_cut_starsB_qso/   , one would read them all in 10)a) , and plot the histogram. \n",
    "\n",
    "NOTE:  that these points have no correction , they have exactly the same e_ij as from master files . |\n",
    "\n",
    "NOTE : if Fig_3_prereq-get_tau_samples_and_fc.ipynb  has been executed, then we already have all the log(tau) samples, and so JUMP STRAIGHT TO PART 10)a) : plotting \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from astroML.stats import median_sigmaG\n",
    "from scipy.stats import binned_statistic\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping CRTS-SDSS quasars catalog from  CRTS_SDSS_cross_matched_qso_DB_QSO_catalog.txt  ...\n",
      "Read in  7601 , quasars from CRTS\n",
      "zipping CRTS-SDSS stars catalog...\n"
     ]
    }
   ],
   "source": [
    "def get_qso_catalog(catalog):\n",
    "    if catalog == 's82drw':\n",
    "        File = 'CRTS_SDSS_cross_matched_qso_s82drw_catalog.txt'\n",
    "    if catalog == 'DB_QSO':\n",
    "        File = 'CRTS_SDSS_cross_matched_qso_DB_QSO_catalog.txt'\n",
    "    colnames = open(File,'r').read().splitlines()[0][1:].split()\n",
    "    datatable = np.genfromtxt(File, dtype=str)\n",
    "    qso_catalog = {}\n",
    "    print 'Zipping CRTS-SDSS quasars catalog from ', File, ' ...'\n",
    "    for label, column in zip(colnames, datatable.T):\n",
    "        qso_catalog[label] = column\n",
    "    \n",
    "    print 'Read in ', len(qso_catalog['redshift']), ', quasars from CRTS'\n",
    "    return  colnames, qso_catalog\n",
    "    \n",
    "def get_stars_catalog():\n",
    "    File = 'CRTS_SDSS_cross_matched_stars_catalog.txt'\n",
    "    colnames = open(File,'r').read().splitlines()[0][1:].split()\n",
    "    datatable = np.genfromtxt(File)\n",
    "    stars_catalog = {}\n",
    "    print 'zipping CRTS-SDSS stars catalog...'\n",
    "    for label, column in zip(colnames, datatable.T):\n",
    "        stars_catalog[label] = column\n",
    "        \n",
    "    return  colnames, stars_catalog\n",
    "\n",
    "cols1, qso_cat = get_qso_catalog(catalog='DB_QSO') \n",
    "cols2 , star_cat= get_stars_catalog()\n",
    "\n",
    "# Perform cuts \n",
    "def cut_qso(qso_cat=qso_cat, mMin=-9, mMax=19, \n",
    "            mErrMin = -9, mErrMax = 0.3,cut_mag='r', report_mag = 'r'):\n",
    "\n",
    "    mask_mag = (qso_cat[cut_mag].astype(float) > mMin) * (qso_cat[cut_mag].astype(float) < mMax) \n",
    "    mask_err = (qso_cat['CRTS_avg_e'].astype(float) > mErrMin) * (qso_cat['CRTS_avg_e'].astype(float) < mErrMax)\n",
    "    mask = mask_mag * mask_err \n",
    "    qso_id = qso_cat['CRTS_id'][mask]\n",
    "    qso_mags = qso_cat[report_mag][mask]\n",
    "    print '\\n These cuts reduced the number of qso  in the sample from', \\\n",
    "          len(qso_cat['redshift']), ' to ', len(qso_id)\n",
    "    return  qso_id\n",
    "\n",
    "def cut_stars(star_cat=star_cat, mMin=-9, mMax=19, mErrMin = -9, \n",
    "              mErrMax = 0.3, gi_Min = -1, gi_Max=1 , cut_mag='r_mMed',\n",
    "              report_mag = 'r_mMed'):\n",
    "\n",
    "    mask_mag = (star_cat[cut_mag] > mMin) * (star_cat[cut_mag] < mMax) \n",
    "    mask_err = (star_cat['CRTS_Merr'] > mErrMin) * (star_cat['CRTS_Merr'] < mErrMax)\n",
    "    SDSS_gi = star_cat['g_mMed'] - star_cat['i_mMed']\n",
    "    mask_color = (SDSS_gi > gi_Min ) * (SDSS_gi < gi_Max)\n",
    "    mask = mask_mag * mask_err * mask_color\n",
    "    star_id_f = star_cat['crts_id'][mask]\n",
    "    star_mags = star_cat[report_mag][mask]\n",
    "    # convert floats to strings without comma and zeros\n",
    "    star_id = np.array([\"{:.0f}\".format(name) for name in star_id_f])\n",
    "    print '\\n These cuts reduced the number of stars  in the sample from', \\\n",
    "          len(star_cat['CRTS_M']), ' to ', len(star_id)\n",
    "    return  star_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Read in points  m_ij , e_ij , tau  from master files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using now only lightcurves with SDSS  18.000000< r < 18.200000\n",
      "\n",
      " Reporting SDSS r  \n",
      "\n",
      " These cuts reduced the number of stars  in the sample from 47787  to  561\n",
      "\n",
      " These cuts reduced the number of stars  in the sample from 47787  to  810\n",
      "\n",
      " These cuts reduced the number of qso  in the sample from 7601  to  127\n"
     ]
    }
   ],
   "source": [
    "Min = 18\n",
    "Max = 18.2\n",
    "magnitudes = ['r']  # don't need g magnitude , decided to use only r magnitude \n",
    "\n",
    "objects_in_cut = {}\n",
    "\n",
    "for mag in magnitudes : \n",
    "    cut_mag = mag\n",
    "    report_mag = mag\n",
    "    \n",
    "    print('\\nUsing now only lightcurves with SDSS  %f< %s < %f' % (Min, cut_mag, Max))\n",
    "    print('\\n Reporting SDSS %s  '% report_mag)\n",
    "\n",
    "    good_ids_S_blue = cut_stars(mMin = Min, mMax=Max, mErrMax = 0.3, gi_Min = -1,\n",
    "                                              gi_Max=1, cut_mag=cut_mag + '_mMed', \n",
    "                                              report_mag=report_mag + '_mMed')\n",
    "    \n",
    "    good_ids_S_red = cut_stars(mMin = Min, mMax=Max, mErrMax = 0.3, gi_Min = 1, \n",
    "                                           gi_Max=3, cut_mag=cut_mag + '_mMed', \n",
    "                                           report_mag=report_mag + '_mMed')\n",
    "    \n",
    "    good_ids_QSO = cut_qso(mMin = Min, mMax=Max, mErrMax = 0.3, \n",
    "                                               cut_mag=cut_mag,report_mag=report_mag)\n",
    "    objects_in_cut[mag] = {'starsB':good_ids_S_blue, 'starsR':good_ids_S_red, \n",
    "                           'qso':good_ids_QSO}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since I'm only using r_cut,   I won't compare it with g_cut .  Thus making r_bin is the same as r_cut  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = {}\n",
    "bin_types = ['r_cut']  # removed 'g_cut'\n",
    "\n",
    "objects = objects_in_cut['r'].keys()\n",
    "\n",
    "# first need to explicitly initialize the dictionaries \n",
    "for b in bin_types:\n",
    "    bins[b] = {}\n",
    "    \n",
    "for obj in objects : \n",
    "    bins['r_cut'][obj] =  objects_in_cut['r'][obj]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the xi, ei for objects in the r_cut ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inside the main loop : get tau, delflx from a master file, either qso or star\n",
    "def add_tau_delflx(File, inDir, data, fc):\n",
    "    # read in storage arrays\n",
    "    delflx = data[0]  \n",
    "    tau = data[1]\n",
    "    err = data[2]\n",
    "    master_acc_list = data[3]   \n",
    "    \n",
    "    # grab the object name \n",
    "    master_name = File[3:-4]\n",
    "    \n",
    "    # read in the i-th master file \n",
    "    master =  np.genfromtxt(inDir+File, dtype=str)\n",
    "    \n",
    "    # read in tau,  del_mag,  del_mag_err for quasars on the list \n",
    "    delflx = np.append(delflx, master[:,0].astype(float))\n",
    "    tau = np.append(tau, master[:,1].astype(float))\n",
    "    \n",
    "    if fc is not None :  # correct new master rows only if  asked for \n",
    "        err = np.append(err, master[:,2].astype(float)*fc)\n",
    "    else:                # otherwise read in without any correction\n",
    "        err = np.append(err, master[:,2].astype(float))\n",
    "    master_names  = np.append(master_acc_list, np.array(len(master[:,0])*[master_name]))\n",
    "    \n",
    "    return delflx, tau, err, master_names\n",
    "    \n",
    "def read_xi_ei(inDirStars, good_ids_S_blue, good_ids_S_red, inDirQSO,\n",
    "                 good_ids_QSO, xi_ei_data=None, fc=None):\n",
    "                     \n",
    "    inDir_S       = inDirStars\n",
    "    good_ids_S_blue    = good_ids_S_blue\n",
    "    good_ids_S_red    = good_ids_S_red\n",
    "    inDir_Q       = inDirQSO\n",
    "      \n",
    "    \n",
    "    # Read the Stellar Master file names \n",
    "    masterFiles_S = os.listdir(inDir_S)\n",
    "    masterFilesS1 = [name[3:-4] for name in masterFiles_S]\n",
    "    \n",
    "    good_masterSB = np.array(masterFiles_S)[np.in1d(masterFilesS1, good_ids_S_blue)]\n",
    "    good_masterSR = np.array(masterFiles_S)[np.in1d(masterFilesS1, good_ids_S_red)]\n",
    "    \n",
    "    # Read the QSO Master file names \n",
    "    masterFiles_Q = os.listdir(inDir_Q)\n",
    "    masterFilesQ1 = [name[3:-4] for name in masterFiles_Q]\n",
    "    good_masterQ = np.array(masterFiles_Q)[np.in1d(masterFilesQ1, good_ids_QSO)]\n",
    "    \n",
    "\n",
    "  \n",
    "    # If no previous read-in xi, ei exists, initialize arrays    \n",
    "    if xi_ei_data is None : \n",
    "        print 'making new delflx, tau, xi arrays'\n",
    "        delflx_S      = np.empty(0,dtype=float)\n",
    "        tau_S         = np.empty(0,dtype=float)\n",
    "        err_S         = np.empty(0,dtype=float)\n",
    "        master_acc_list_S = np.empty(0, dtype=str)\n",
    "    \n",
    "        \n",
    "       \n",
    "        delflx_Q      = np.empty(0,dtype=float)\n",
    "        tau_Q         = np.empty(0,dtype=float)\n",
    "        err_Q         = np.empty(0,dtype=float)\n",
    "        master_acc_list_Q = np.empty(0, dtype=str)\n",
    "        \n",
    "        # Initialize the data structures to which more and more delta_t and delta_mag\n",
    "        # are addded from each consecutive master file \n",
    "        qso_data = [delflx_Q, tau_Q, err_Q, master_acc_list_Q] \n",
    "        star_data_blue = [delflx_S, tau_S, err_S, master_acc_list_S]\n",
    "        star_data_red  = [delflx_S, tau_S, err_S, master_acc_list_S]\n",
    "        \n",
    "    else:\n",
    "        print 'using existing xi ei arrays'\n",
    "        qso_data = xi_ei_data[0]\n",
    "        star_data_blue = xi_ei_data[1]\n",
    "        star_data_red = xi_ei_data[2]\n",
    "        \n",
    "    print('\\n')\n",
    "    c = 0\n",
    "    for File in good_masterQ: #  len(masterFiles_Q)\n",
    "        qso_data = add_tau_delflx(File,inDir_Q, qso_data, fc)\n",
    "        c += 1 \n",
    "        if c % 5 == 0:\n",
    "            pers = (100.0*c) / float(len(good_masterQ))\n",
    "            print('\\r----- Already read %d%% of qso'%pers),\n",
    "    \n",
    "    print('\\n')\n",
    "    c = 0                   \n",
    "    for File in good_masterSB:    # [:len(good_masterQ)]\n",
    "        star_data_blue = add_tau_delflx(File, inDir_S,star_data_blue, fc)\n",
    "        c += 1 \n",
    "        if c % 5 == 0:\n",
    "            pers = (100.0*c) / float(len(good_masterSB))\n",
    "            print('\\r----- Already read %d%% of Blue Stars'%pers),  \n",
    "    print('\\n')\n",
    "    c = 0                         \n",
    "    for File in good_masterSR:   # [:len(good_masterQ)]\n",
    "        star_data_red = add_tau_delflx(File, inDir_S, star_data_red, fc)      \n",
    "        c += 1               \n",
    "        if c % 5 == 0:\n",
    "            pers = (100.0*c) / float(len(good_masterSR))\n",
    "            print('\\r----- Already read %d%% of Red Stars'%pers),          \n",
    "                     \n",
    "    print('returning xi, ei for ... %d objects'%len(good_masterQ))\n",
    "                            \n",
    "    return  qso_data, star_data_blue, star_data_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in xi, ei for bin  r_cut\n",
      "making new delflx, tau, xi arrays\n",
      "\n",
      "\n",
      "----- Already read 98% of qso \n",
      "\n",
      "----- Already read 99% of Blue Stars \n",
      "\n",
      "----- Already read 100% of Red Stars returning xi, ei for ... 127 objects\n"
     ]
    }
   ],
   "source": [
    "inDirStars   = 'sf_file_per_LC/star/'\n",
    "inDirQSO = 'sf_file_per_LC/qso/'\n",
    "\n",
    "out_dic = {}\n",
    "\n",
    "#for b in bins.keys():\n",
    "# read in only r_cut \n",
    "\n",
    "b = 'r_cut'\n",
    "print 'Reading in xi, ei for bin ', b\n",
    "out_dic[b] = {}   # initialize the dic \n",
    "\n",
    "good_ids_S_blue = bins[b]['starsB']\n",
    "good_ids_S_red = bins[b]['starsR']\n",
    "good_ids_QSO = bins[b]['qso']\n",
    "\n",
    "qso, starB, starR = read_xi_ei(inDirStars, good_ids_S_blue, good_ids_S_red, inDirQSO,\n",
    "              good_ids_QSO,xi_ei_data=None, fc=None)\n",
    "\n",
    "# put into a dictionary : makes it more explicit \n",
    "out_dic[b] = {'starsB': starB, 'starsR': starR, 'qso':qso}\n",
    "\n",
    "\n",
    "# Straight after reading-in xi, ei,   one can proceed directly to part 9) (one bin) or 10 : all bins sigma comparison \n",
    "# or to Saving just the log(tau) samples of xi, tau, ei. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10) Save to a file all points for samples of log(tau) for a given mag cut "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save to a file points for log(tau) samples  for QSO, stars \n",
    "\n",
    "b = 'r_cut'   # or g_cut\n",
    "\n",
    "tau_min_arr = [0,   2.3, 2.8, 3.2]\n",
    "tau_max_arr = [1.7, 2.5, 3.0, 3.4]\n",
    "for obj in ['qso','starsB']:\n",
    "    #obj = 'qso'  # or starsB,  starsR \n",
    "    m_ij = out_dic[b][obj][0]\n",
    "    tau =  out_dic[b][obj][1]\n",
    "    e_ij =  out_dic[b][obj][2]\n",
    "    \n",
    "    for i in range(len(tau_min_arr)):\n",
    "        m1 = tau_min_arr[i] < np.log10(tau)\n",
    "        m2 = np.log10(tau) < tau_max_arr[i]\n",
    "        mask =  m1 * m2 \n",
    "\n",
    "        data = np.column_stack((m_ij[mask], tau[mask], e_ij[mask]))\n",
    "        figtitle = b+'_'+str(Min)+'-'+str(Max)+'_'+obj+'_fc-'+str(fc)+'_SF.png'\n",
    "\n",
    "        fname = b+'_'+str(Min)+'-'+str(Max)+'_'+obj+'_mi_tau_ei-log_tau_'+\\\n",
    "                str(tau_min_arr[i])+'-'+str(tau_max_arr[i])+'.txt'\n",
    "        print 'Saved', fname\n",
    "        np.savetxt(fname, data, fmt='%s', delimiter= ' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10)a) Plot the histogram grid for qso and starsB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is taken from poster_hist_r_cut_qso_starsB_mag_tau_grid.py  program\n",
    "\n",
    "b = 'r_cut'\n",
    "d = 'Histograms_r_cut_starsB_QSO_tabelka/'\n",
    "\n",
    "def plot2Chistograms(chiQSO, chiSTAR, Xmin, Xmax, Ymin, Ymax, Xlabel, Ylabel, ax, bins=20, title=''):\n",
    "    limits = [(Xmin, Xmax, Ymin, Ymax)]\n",
    "    labels = [Xlabel, Ylabel]\n",
    "    ax.set_xlim(Xmin, Xmax)\n",
    "    ax.set_ylim(Ymin, Ymax)\n",
    "    ax.set_xlabel(Xlabel, fontsize=12)\n",
    "    ax.set_ylabel(Ylabel, fontsize=12)\n",
    "    #plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    xTitle = Xmin + 0.05*(Xmax-Xmin)\n",
    "    yTitle = Ymax - 0.2*(Ymax-Ymin)\n",
    "    ax.text(xTitle, yTitle, title, fontsize=12)\n",
    "\n",
    "    # plot a histogram\n",
    "    ax.hist(chiSTAR, bins=bins, normed=True, facecolor='blue', histtype='stepfilled', alpha=0.4)\n",
    "    ax.hist(chiQSO, bins=bins, normed=True, facecolor='red', histtype='stepfilled', alpha=0.2)\n",
    "\n",
    "    # plot the robust width of both distributions\n",
    "    stdev_rob_QSO = 0.7414 *(np.percentile(chiQSO,75) - np.percentile(chiQSO,25) )\n",
    "    stdev_rob_S = 0.7414 *(np.percentile(chiSTAR,75) - np.percentile(chiSTAR,25) )\n",
    "    \n",
    "    #al_Q = 0.4\n",
    "    #al_S = 0.2\n",
    "    #s = '--'\n",
    "    #w = 1.5\n",
    "    #c = 0.5\n",
    "    # below ymin, ymax in the absolute 0-1 units!  \n",
    "    #ax.axvline(x =stdev_rob_S ,ymin=0, ymax=c, color='red', lw=w, ls=s, alpha=al_S)\n",
    "    #ax.axvline(x =stdev_rob_S ,ymin=0, ymax=c, color='red', lw=w, ls=s, alpha=al_S)\n",
    "    #ax.axvline(x =stdev_rob_QSO ,ymin=0, ymax=c, color='blue', lw=w, ls=s, alpha=al_Q)\n",
    "    #ax.axvline(x =stdev_rob_QSO , ymin=0, ymax=c, color='blue', lw=w, ls=s, alpha=al_Q)\n",
    "    #ax.axvline(x =-stdev_rob_S , ymin=0, ymax=c,color='red', lw=w, ls=s, alpha=al_S)\n",
    "    #ax.axvline(x =-stdev_rob_S , ymin=0, ymax=c,color='red', lw=w, ls=s, alpha=al_S)\n",
    "    #ax.axvline(x =-stdev_rob_QSO ,ymin=0, ymax=c, color='blue', lw=w, ls=s, alpha=al_Q)\n",
    "    #ax.axvline(x =-stdev_rob_QSO , ymin=0, ymax=c,color='blue', lw=w, ls=s, alpha=al_Q)\n",
    "   \n",
    "    xTitle = Xmin + 0.65*(Xmax-Xmin)\n",
    "    yTitle = Ymax - 0.2*(Ymax-Ymin)\n",
    "    StarSigmaG = r'$'+str(stdev_rob_S)[:4]+'$'\n",
    "    ax.text(xTitle, yTitle, StarSigmaG, fontsize=12)\n",
    "    \n",
    "    \n",
    "    xTitle = Xmin + 0.65*(Xmax-Xmin)\n",
    "    yTitle = Ymax - 0.35*(Ymax-Ymin)\n",
    "    QSOSigmaG = r'$'+str(stdev_rob_QSO)[:4]+'$'\n",
    "    ax.text(xTitle, yTitle, QSOSigmaG, fontsize=12)\n",
    "    \n",
    "    \n",
    "Min_arr = [17, 18, 18.5]\n",
    "Max_arr = [18, 18.5, 19]\n",
    "tau_min_arr = [0,   2.3, 2.8, 3.2]\n",
    "tau_max_arr = [1.7, 2.5, 3.0, 3.4]\n",
    "xlims_arr = [5,10,10,10]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just for testing  - load only 1/16 files (one for QSO one for Stars) and experiment with how it looks \n",
    "datafileS = d+b+'_'+str(Min_arr[j])+'-'+str(Max_arr[j])+'_'+'starsB'+'_mi_tau_ei-log_tau_'+\\\n",
    "                        str(tau_min_arr[i])+'-'+str(tau_max_arr[i])+'.txt'\n",
    "vS = np.loadtxt(datafileS, unpack=True)\n",
    "\n",
    "datafileQ = d+b+'_'+str(Min_arr[j])+'-'+str(Max_arr[j])+'_'+'qso'+'_mi_tau_ei-log_tau_'+\\\n",
    "        str(tau_min_arr[i])+'-'+str(tau_max_arr[i])+'.txt'\n",
    "vQ = np.loadtxt(datafileQ, unpack=True)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving plot to: Fig_3_histogram_panels.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib \n",
    "matplotlib.rc('xtick', labelsize=15) \n",
    "matplotlib.rc('ytick', labelsize=15) \n",
    "\n",
    "fig, axs = plt.subplots(4,3, figsize=(8, 8))\n",
    "fig.subplots_adjust(wspace=0.46, hspace=0.36, left=0.12, right=0.94, bottom=0.05, top=0.95)\n",
    "\n",
    "for i in range(len(tau_max_arr)):  # \n",
    "    for j in range(len(Min_arr) ):  # \n",
    "       \n",
    "\n",
    "        datafileS = d+b+'_'+str(Min_arr[j])+'-'+str(Max_arr[j])+'_'+'starsB'+'_mi_tau_ei-log_tau_'+\\\n",
    "                        str(tau_min_arr[i])+'-'+str(tau_max_arr[i])+'.txt'\n",
    "        vS = np.loadtxt(datafileS, unpack=True)\n",
    "        chiS = vS[0]/vS[2]\n",
    "        chiSok = chiS[np.abs(chiS)<5]\n",
    "        \n",
    "        datafileQ = d+b+'_'+str(Min_arr[j])+'-'+str(Max_arr[j])+'_'+'qso'+'_mi_tau_ei-log_tau_'+\\\n",
    "                str(tau_min_arr[i])+'-'+str(tau_max_arr[i])+'.txt'\n",
    "        vQ = np.loadtxt(datafileQ, unpack=True)\n",
    "        chiQ = vQ[0]/vQ[2]\n",
    "        chiQok = chiQ[np.abs(chiQ)<xlims_arr[i]]\n",
    "\n",
    "        # plot histograms\n",
    "        Xlabel = '$\\chi = \\Delta mag / error$'\n",
    "        Ylabel = '$n / (N\\Delta_{bin})$'\n",
    "        Xmin = -xlims_arr[i]\n",
    "        Xmax = xlims_arr[i]\n",
    "        bins = 40 \n",
    "        title= r'$ '+' '+ str(tau_min_arr[i])+'-'+str(tau_max_arr[i])+'$'\n",
    "        plot2Chistograms(chiQok, chiSok, Xmin=Xmin, Xmax=Xmax, Ymin=0.0, \n",
    "                             Ymax=0.55, Xlabel=Xlabel, Ylabel=Ylabel, ax=axs[i,j],bins=bins,  \n",
    "                         title=title)\n",
    "\n",
    "#name = 'poster_r_cut_qso_starsB_histogram_grid.png'\n",
    "name = 'Fig_3_histogram_panels.png'\n",
    "if (name is None):\n",
    "    plt.show() \n",
    "else:\n",
    "    print 'saving plot to:', name\n",
    "    plt.savefig(name, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
